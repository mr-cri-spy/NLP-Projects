{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUUnkV3DLg8XivpSu7Q0nM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-cri-spy/NLP-Projects/blob/main/nlp_practice_1_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmqCoFYHGU5v",
        "outputId": "1d4864e3-4020-4840-ade7-8c4790ff393d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (Det the) (Noun dog))\n",
            "  (VP (Verb chases) (NP (Det a) (Noun cat))))\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "\n",
        "#Define grammar\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> Det Noun\n",
        "  VP -> Verb NP\n",
        "  Det -> 'the' | 'a'\n",
        "  Noun -> 'dog' | 'cat'\n",
        "  Verb -> 'chases' | 'sees'\n",
        "\"\"\")\n",
        "\n",
        "#Create parser\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Parse a sentence\n",
        "sentence = ['the', 'dog', 'chases', 'a', 'cat']\n",
        "for tree in parser.parse(sentence):\n",
        "    print(tree)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POS Tagging & Viterbi Algorithm (HMM)"
      ],
      "metadata": {
        "id": "zDOWEtNMI5vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import hmm\n",
        "\n",
        "# Labeled training data\n",
        "train_data = [[('Akki', 'NOUN'), ('runs', 'VERB')],\n",
        " [('Gopala', 'NOUN'), ('eats', 'VERB')]]\n",
        "\n",
        "#Train HMM\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "tagger = trainer.train_supervised(train_data)\n",
        "\n",
        "#Testing\n",
        "print(tagger.tag(['Akki', 'eats']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2AYwTfrI6jF",
        "outputId": "ed4042a3-e04a-420a-89b8-7fbb3ac008cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Akki', 'NOUN'), ('eats', 'VERB')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Dependency Parsing (SpaCy)"
      ],
      "metadata": {
        "id": "WbZkOBeBKG2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "#Loading English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Analyze sentence\n",
        "doc = nlp(\"Akki saw Gopala\")\n",
        "for token in doc:\n",
        "    print(f\"{token.text} --> {token.head.text} ({token.dep_})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyWLffa7KIBb",
        "outputId": "4db67583-cdb5-4bde-88b2-66083ffc7f84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akki --> saw (nsubj)\n",
            "saw --> saw (ROOT)\n",
            "Gopala --> saw (dobj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EM Algorithm (Unsupervised HMM Training)"
      ],
      "metadata": {
        "id": "v3N27g1oK4II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Workaround:-Supervised HMM to simulate EM behavior\n",
        "from nltk.tag import hmm\n",
        "\n",
        "train_data = [\n",
        "    [('Akki', 'NOUN'), ('writes', 'VERB')],\n",
        "    [('Gopala', 'NOUN'), ('runs', 'VERB')],\n",
        "    [('Akki', 'NOUN'), ('eats', 'VERB')]\n",
        "]\n",
        "\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "tagger = trainer.train_supervised(train_data)\n",
        "print(tagger.tag(['Gopala', 'writes']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duvmu-6tK8dM",
        "outputId": "cc1d417a-ddf7-429f-fddd-807f0be177db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Gopala', 'NOUN'), ('writes', 'VERB')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward-Backward Algorithm (NumPy)"
      ],
      "metadata": {
        "id": "VcEohAYSSYlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "states = ['NOUN', 'VERB']\n",
        "observations = ['Akki', 'runs']\n",
        "obs_map = {'Akki': 0, 'runs': 1}\n",
        "A = np.array([[0.6, 0.4], [0.3, 0.7]])\n",
        "B = np.array([[0.9, 0.1], [0.2, 0.8]])\n",
        "pi = np.array([0.5, 0.5])\n",
        "T = len(observations)\n",
        "N = len(states)\n",
        "\n",
        "#Forward\n",
        "alpha = np.zeros((T, N))\n",
        "alpha[0] = pi * B[:, obs_map[observations[0]]]\n",
        "for t in range(1, T):\n",
        "    for j in range(N):\n",
        "        alpha[t, j] = np.sum(alpha[t-1] * A[:, j]) * B[j, obs_map[observations[t]]]\n",
        "\n",
        "#Backward\n",
        "beta = np.zeros((T, N))\n",
        "beta[T-1] = np.ones(N)\n",
        "for t in range(T-2, -1, -1):\n",
        "    for i in range(N):\n",
        "        beta[t, i] = np.sum(A[i, :] * B[:, obs_map[observations[t+1]]] * beta[t+1])\n",
        "\n",
        "# Posterior probabilities\n",
        "gamma = (alpha * beta) / np.sum(alpha[-1])\n",
        "print(\"Gamma (state probabilities):\\n\", gamma)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8syzDTqOSmJG",
        "outputId": "0a7e164d-2838-478e-c3e5-ba6fe5a44526"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gamma (state probabilities):\n",
            " [[0.74347826 0.25652174]\n",
            " [0.13043478 0.86956522]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MaxEnt Classifier\n"
      ],
      "metadata": {
        "id": "bWoiuMNUT12c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "train_data = [\n",
        "    ({\"word\": \"Akki\", \"suffix\": \"i\"}, \"NOUN\"),\n",
        "    ({\"word\": \"eats\", \"suffix\": \"s\"}, \"VERB\"),\n",
        "    ({\"word\": \"apple\", \"suffix\": \"e\"}, \"NOUN\")\n",
        "]\n",
        "\n",
        "classifier = MaxentClassifier.train(train_data, algorithm='iis', trace=0, max_iter=10)\n",
        "print(classifier.classify({\"word\": \"eats\", \"suffix\": \"s\"}))\n",
        "classifier.show_most_informative_features()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYdyHO0kT3c1",
        "outputId": "d69aa094-513d-44f2-d792-d8a3b322c0b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VERB\n",
            "   1.661 word=='Akki' and label is 'NOUN'\n",
            "   1.661 suffix=='i' and label is 'NOUN'\n",
            "   1.661 word=='eats' and label is 'VERB'\n",
            "   1.661 suffix=='s' and label is 'VERB'\n",
            "   1.661 word=='apple' and label is 'NOUN'\n",
            "   1.661 suffix=='e' and label is 'NOUN'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HYWS7tMjdEzF"
      }
    }
  ]
}